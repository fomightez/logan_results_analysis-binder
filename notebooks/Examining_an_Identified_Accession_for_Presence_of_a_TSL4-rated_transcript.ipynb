{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining an Identified Accession for Presence of a TSL4-rated transcript\n",
    "\n",
    "This takes an accession identified previously in the last notebook of this series,[Selecting Logan Search results by Sequencing Technology using Python in Jupyter](Selecting_Logan_Search_results_by_Sequencing_Technology_using_Python_in_Jupyter.ipynb), and follows-up to see if a representative of the TSL4-rated transcript ENST00000567329 (USP7-217) can be identified since the query results suggests its presence.\n",
    "\n",
    "**Two important notes about this Jupyter Notebook**\n",
    "- Unlike the prior notebooks in this series, this one is not meant to be run in this session. It has already been run, and so you can review it by scrolling down.\n",
    "\n",
    "  If you did want to run it: This was developed in a blast-binder session launched from [my blast-binder repo](https://github.com/fomightez/blast-binder) (note that also has PatMatch installed, but that software wasn't used here â€” although earlier I checked some preliminary results using it and have noted that here).  \n",
    "  Follow the directions below to launch yet another mybinder-served session and bring this notebook over to that session.\n",
    "  \n",
    "- it is a rough sketch of an analysis at this stage\n",
    "\n",
    "  There's a lot of USP7-related transcripts and this is only rough classification that doesn't take this into account. It is done to simply give a general idea of the TSL4-rated transcript relative other USP7 transcripts.\n",
    "\n",
    "\n",
    "**IMPORTANT- STEP-BY-STEP HOW TO RUN THIS NOTEBOOK, IF YOU NEED TO:**  \n",
    "\n",
    "If you are reading this in an active session launched from [the 'logan_results_analysis-binder'](https://github.com/fomightez/logan_results_analysis-binder) as intended, you should be able to review this notebook pre-run and examine all the results. However, if you did want to run it.\n",
    "As mentioned above, this needs to be run in a different session with BLAST software available. This is to keep the current environment less complex at this time as only this last notebook needs that.\n",
    "- Right-click on the following link and choose to open it in a new browser window so that you can continue to read this: [click this](https://mybinder.org/v2/gh/fomightez/blast-binder/master?urlpath=%2Flab%2Ftree)\n",
    "- When the session spins up, open a new notebook backed by a Python kernel by clicking on the upper left tile in the main Jupyter pane and then use copy-and-paste to run the following command in it:\n",
    "\n",
    "```shell\n",
    "!curl -OL https://raw.githubusercontent.com/fomightez/logan_results_analysis-binder/refs/heads/main/notebooks/Examining_an_Indentified_Accession_for_Presence_of_a_TSL4-rated_transcript.ipynb\n",
    "```\n",
    "\n",
    "- After a few seconds the notebook `Examining_an_Indentified_Accession_for_Presence_of_a_TSL4-rated_transcript.ipynb` should show up in the file browser pane on the left. Now you are ready to run that.\n",
    "\n",
    "- Double-click on the notebook `Examining_an_Indentified_Accession_for_Presence_of_a_TSL4-rated_transcript.ipynb` to open it.\n",
    "\n",
    "- When the notebook opens start running the sections below this point and continue on using the notebook there. Importantly, if you modify `Examining_an_Indentified_Accession_for_Presence_of_a_TSL4-rated_transcript.ipynb` and make soemthing useful, be sure to download and keep that version as this one is no way connected to it.\n",
    "\n",
    "Actual content continues below...\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation for Analysis STAGE 1, Looking into identified accession & mapping its reads\n",
    "\n",
    "In the previous notebook in this series, [Selecting Logan Search results by Sequencing Technology using Python in Jupyter](Selecting_Logan_Search_results_by_Sequencing_Technology_using_Python_in_Jupyter.ipynb), one of the accessions with long reads identified was `SRR23849628`. \n",
    "\n",
    "The Logan Search data does include a substantial amount of metadata and examining the row in that notebook might show tissue source of the data. In the case of `SRR23849628`, I don't see that as the case.  \n",
    "However, we need additional metadata not there, such as URLs to retrieve the data. And it is also nice to know how to programmatically access the metadata, and so we'll use the packages `ffq` and `bio` here to access such metata.\n",
    "\n",
    "More about the two packages, with additional demonstrations can be found [here](https://www.biostars.org/p/9522636/#) and in [my demonstration notebook, 'demo ffq for finding sequencing data and metadata from public databases'](https://nbviewer.org/github/fomightez/cl_sq_demo-binder/blob/master/notebooks/demo%20ffq%20for%20finding%20sequencing%20data%20and%20metadata%20from%20public%20databases.ipynb), found in [my cl_sq_demo-binder repo](https://github.com/fomightez/cl_sq_demo-binder).\n",
    "\n",
    "Let's first run the next cell to install the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ffq bio -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Analysis STAGE 1, Looking into identified accession & mapping its reads\n",
    "\n",
    "With the preparaton out of the way, we can use the packages to look at the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-17 20:14:05,029]    INFO Parsing run SRR23849628\n",
      "{\n",
      "    \"SRR23849628\": {\n",
      "        \"accession\": \"SRR23849628\",\n",
      "        \"experiment\": \"SRX19662564\",\n",
      "        \"study\": \"SRP410260\",\n",
      "        \"sample\": \"SRS17033009\",\n",
      "        \"title\": \"PromethION sequencing; GSM7093690: 35cycle_10X; Homo sapiens; RNA-Seq\",\n",
      "        \"attributes\": {\n",
      "            \"ENA-FIRST-PUBLIC\": \"2023-06-23\",\n",
      "            \"ENA-LAST-UPDATE\": \"2023-06-23\"\n",
      "        },\n",
      "        \"files\": {\n",
      "            \"ftp\": [\n",
      "                {\n",
      "                    \"accession\": \"SRR23849628\",\n",
      "                    \"filename\": \"SRR23849628_1.fastq.gz\",\n",
      "                    \"filetype\": \"fastq\",\n",
      "                    \"filesize\": 10790875511,\n",
      "                    \"filenumber\": 1,\n",
      "                    \"md5\": \"05b77f9a3d01bd63e66b796c16e86b90\",\n",
      "                    \"urltype\": \"ftp\",\n",
      "                    \"url\": \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR238/028/SRR23849628/SRR23849628_1.fastq.gz\"\n",
      "                }\n",
      "            ],\n",
      "            \"aws\": [],\n",
      "            \"gcp\": [],\n",
      "            \"ncbi\": []\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!ffq SRR23849628"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, often there will be `aws` and `ncbi` URLs. (It seems ones deposited at the UK ebi aren't propagated to the other resources. And so options are more limited than you'll typically observe.)\n",
    "\n",
    "I've noted with `ffq`, you get more associated metadata if you use the 'sample' listed for the query (not the same as the 'BioSample' that begins usually with `SAMN`). The one above shows `SRS17033009` for 'sample' and so let's run that, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-17 20:14:06,938]    INFO Parsing sample SRS17033009\n",
      "[2025-04-17 20:14:07,105] WARNING Failed to parse sample information from ENA XML. Falling back to ENA search...\n",
      "[2025-04-17 20:14:07,243]    INFO Getting Experiment for SRS17033009\n",
      "[2025-04-17 20:14:07,243]    INFO Parsing Experiment SRX19662564\n",
      "[2025-04-17 20:14:07,403] WARNING Failed to parse experiment information from ENA XML. Falling back to ENA search...\n",
      "[2025-04-17 20:14:07,540] WARNING There is 1 run for SRX19662564\n",
      "[2025-04-17 20:14:07,540]    INFO Parsing run SRR23849628\n",
      "{\n",
      "    \"SRS17033009\": {\n",
      "        \"accession\": \"SRS17033009\",\n",
      "        \"title\": \"35cycle_10X\",\n",
      "        \"organism\": \"Homo sapiens\",\n",
      "        \"attributes\": {\n",
      "            \"collection_date\": \"missing\",\n",
      "            \"treatment\": \"35cycles\",\n",
      "            \"INSDC secondary accession\": \"SRS17033009\",\n",
      "            \"NCBI submission package\": \"Generic.1.0\",\n",
      "            \"organism\": \"Homo sapiens\",\n",
      "            \"geo_loc_name\": \"missing\",\n",
      "            \"cell type\": \"Myeloma cell lines (2000 cells)\",\n",
      "            \"cell line\": \"JJN3 and 5TGMG1\",\n",
      "            \"source_name\": \"JJN3 and 5TGMG1\",\n",
      "            \"BioSampleModel\": \"Generic\",\n",
      "            \"ENA-FIRST-PUBLIC\": \"2023-06-01\",\n",
      "            \"ENA-LAST-UPDATE\": \"2023-06-02\"\n",
      "        },\n",
      "        \"experiments\": {\n",
      "            \"SRX19662564\": {\n",
      "                \"accession\": \"SRX19662564\",\n",
      "                \"title\": \"GSM7093690: 35cycle_10X; Homo sapiens; RNA-Seq\",\n",
      "                \"platform\": \"OXFORD_NANOPORE\",\n",
      "                \"instrument\": \"PromethION\",\n",
      "                \"runs\": {\n",
      "                    \"SRR23849628\": {\n",
      "                        \"accession\": \"SRR23849628\",\n",
      "                        \"experiment\": \"SRX19662564\",\n",
      "                        \"study\": \"SRP410260\",\n",
      "                        \"sample\": \"SRS17033009\",\n",
      "                        \"title\": \"PromethION sequencing; GSM7093690: 35cycle_10X; Homo sapiens; RNA-Seq\",\n",
      "                        \"attributes\": {\n",
      "                            \"ENA-FIRST-PUBLIC\": \"2023-06-23\",\n",
      "                            \"ENA-LAST-UPDATE\": \"2023-06-23\"\n",
      "                        },\n",
      "                        \"files\": {\n",
      "                            \"ftp\": [\n",
      "                                {\n",
      "                                    \"accession\": \"SRR23849628\",\n",
      "                                    \"filename\": \"SRR23849628_1.fastq.gz\",\n",
      "                                    \"filetype\": \"fastq\",\n",
      "                                    \"filesize\": 10790875511,\n",
      "                                    \"filenumber\": 1,\n",
      "                                    \"md5\": \"05b77f9a3d01bd63e66b796c16e86b90\",\n",
      "                                    \"urltype\": \"ftp\",\n",
      "                                    \"url\": \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR238/028/SRR23849628/SRR23849628_1.fastq.gz\"\n",
      "                                }\n",
      "                            ],\n",
      "                            \"aws\": [],\n",
      "                            \"gcp\": [],\n",
      "                            \"ncbi\": []\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!ffq SRS17033009"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That indicates the source of this sequence data is: 'Myeloma cell lines'.\n",
    "\n",
    "Let's do this with `bio` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"run_accession\": \"SRR23849628\",\n",
      "        \"sample_accession\": \"SAMN33743856\",\n",
      "        \"sample_alias\": \"GSM7093690\",\n",
      "        \"sample_description\": \"35cycle_10X\",\n",
      "        \"first_public\": \"2023-06-23\",\n",
      "        \"country\": \"missing\",\n",
      "        \"scientific_name\": \"Homo sapiens\",\n",
      "        \"fastq_bytes\": \"10790875511\",\n",
      "        \"base_count\": \"10715195111\",\n",
      "        \"read_count\": \"6444874\",\n",
      "        \"library_name\": \"GSM7093690\",\n",
      "        \"library_strategy\": \"RNA-Seq\",\n",
      "        \"library_source\": \"TRANSCRIPTOMIC\",\n",
      "        \"library_layout\": \"SINGLE\",\n",
      "        \"instrument_platform\": \"OXFORD_NANOPORE\",\n",
      "        \"instrument_model\": \"PromethION\",\n",
      "        \"study_title\": \"Counting and correcting errors within unique molecular identifiers to generate absolute numbers of sequencing molecules [scRNA-Seq]\",\n",
      "        \"fastq_url\": [\n",
      "            \"https://ftp.sra.ebi.ac.uk/vol1/fastq/SRR238/028/SRR23849628/SRR23849628_1.fastq.gz\"\n",
      "        ],\n",
      "        \"info\": \"11 GB files; 6.4 million reads; 10715.2 million sequenced bases\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!bio search SRR23849628"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reports number of reads as 6.4 million.  \n",
    "Hmmm... in this case `bio search` doesn't give the source of the data as clear as `ffq` does. It is atypical, though as seen from this unrelated example `!bio search SRR17607594` if you care to run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the difference of the software results with the same identifiers, and ffq being better when using 'sample', it is good to look at a few examples and make sure you follow-up on any dead ends you seem to hit with one software, perhaps with another.\n",
    "\n",
    "In this case, both give the same URLs for retrieval of the data; however, as I said though `ffq` will typically offer you more options for retrieval. Even in cases where other options exist, `bio search` won't feature the other URLs, at least currently. (You can convince yourself of this running `!ffq ERR5670887` vs. `!bio search ERR5670887`. The data there is not related to here, but illustrates what I am saying.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that URL, Minimap2 was used to do alignment with the data in accession `SRR23849628` to the human genome, specifically [Genome Reference Consortium Human GRCh38.p14/hg38](https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz).\n",
    "\n",
    "I used `samtools view` to limit the data to reads that map to the USP7 locus, plus/minus 10 bps (human chr16:8892087-8975338).\n",
    "\n",
    "I have supplied the resulting pertinent data & output here for examination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Preparation for Analysis STAGE 2, Running this notebook using data collected by mapping reads\n",
    "\n",
    "Now already have generated `USP7_locus_mapped_SRX19662564_reads.fastq` which came from running minimap with the identified accession `SRR23849628 `. More about that below. We'll just need to bring it to this active session.\n",
    "\n",
    "Likewise, will need to bring here the already-generated files:\n",
    "- `mapped_stats_all_reads_$(ENA_EXPERIMENT).tsv`\n",
    "- `mapped_stats_just_USP7_locus_$(ENA_EXPERIMENT).tsv`\n",
    "- `Homo_sapiens_ENST00000344836_9_sequence_USP7-MANE_trancript.fasta`\n",
    "- `Homo_sapiens_ENST00000567329_1_sequence_USP7-217_trancript.fasta`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to get all those and place them where expected in this active session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'logan_results_analysis-binder'...\n",
      "remote: Enumerating objects: 371, done.\u001b[K\n",
      "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
      "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
      "remote: Total 371 (delta 46), reused 59 (delta 27), pack-reused 292 (from 1)\u001b[K\n",
      "Receiving objects: 100% (371/371), 40.74 MiB | 23.72 MiB/s, done.\n",
      "Resolving deltas: 100% (239/239), done.\n",
      "Cloned successfully...continuing on..\n",
      "mv: cannot move 'logan_results_analysis-binder/notebooks/supporting_tables_and_data/' to './supporting_tables_and_data': Directory not empty\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/fomightez/logan_results_analysis-binder.git && echo \"Cloned successfully...continuing on..\" # `&&` parts makes sure it completes this before contuing on to move\n",
    "!mv logan_results_analysis-binder/notebooks/supporting_tables_and_data/ .\n",
    "!rm -rf logan_results_analysis-binder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to install additional packages needed for the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install pyfaidx\n",
    "%conda install -c bioconda fqgrep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get utility scripts needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 13771  100 13771    0     0  75538      0 --:--:-- --:--:-- --:--:-- 75664\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://raw.githubusercontent.com/fomightez/sequencework/master/blast-utilities/blast_to_df.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Analysis of the Mapped Reads\n",
    "\n",
    "#### Stats about reads mapped\n",
    "\n",
    "Let's look at some details about all the reads mapped from that accession and then focus in on the ones stored in `USP7_locus_mapped_SRX19662564_reads.fastq`.\n",
    "\n",
    "Run the next cell for looking at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10616211\t0\ttotal (QC-passed reads + QC-failed reads)\n",
      "6444874\t0\tprimary\n",
      "2738386\t0\tsecondary\n",
      "1432951\t0\tsupplementary\n",
      "0\t0\tduplicates\n",
      "0\t0\tprimary duplicates\n",
      "9387725\t0\tmapped\n",
      "88.43%\tN/A\tmapped %\n",
      "5216388\t0\tprimary mapped\n",
      "80.94%\tN/A\tprimary mapped %\n",
      "0\t0\tpaired in sequencing\n",
      "0\t0\tread1\n",
      "0\t0\tread2\n",
      "0\t0\tproperly paired\n",
      "N/A\tN/A\tproperly paired %\n",
      "0\t0\twith itself and mate mapped\n",
      "0\t0\tsingletons\n",
      "N/A\tN/A\tsingletons %\n",
      "0\t0\twith mate mapped to a different chr\n",
      "0\t0\twith mate mapped to a different chr (mapQ>=5)\n"
     ]
    }
   ],
   "source": [
    "!cat supporting_tables_and_data/mapped_stats_all_reads_SRX19662564.tsv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the line primary reads number, i.e., `6444874\t0\tprimary`, matches what `!bio search SRR23849628` gave earlier.  \n",
    "Now for just the locus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109\t0\ttotal (QC-passed reads + QC-failed reads)\n",
      "863\t0\tprimary\n",
      "7\t0\tsecondary\n",
      "239\t0\tsupplementary\n",
      "0\t0\tduplicates\n",
      "0\t0\tprimary duplicates\n",
      "1109\t0\tmapped\n",
      "100.00%\tN/A\tmapped %\n",
      "863\t0\tprimary mapped\n",
      "100.00%\tN/A\tprimary mapped %\n",
      "0\t0\tpaired in sequencing\n",
      "0\t0\tread1\n",
      "0\t0\tread2\n",
      "0\t0\tproperly paired\n",
      "N/A\tN/A\tproperly paired %\n",
      "0\t0\twith itself and mate mapped\n",
      "0\t0\tsingletons\n",
      "N/A\tN/A\tsingletons %\n",
      "0\t0\twith mate mapped to a different chr\n",
      "0\t0\twith mate mapped to a different chr (mapQ>=5)\n"
     ]
    }
   ],
   "source": [
    "!cat supporting_tables_and_data/mapped_stats_just_USP7_locus_SRX19662564.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's 863 reads mapped to USP7 out of the 6.4 million included in `SRR23849628`.  \n",
    "Can we see the TSL4-rated one we are interested in and see what percentage it is?\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "#### Analysis of the Mapped Reads for presence of TSL4-rated transcript USP7-217.\n",
    "\n",
    "We now have reads we can mine for information about the transcript of interest, the USP7-217 retained intron-query sequence ENST00000567329 (USP7-217).\n",
    "\n",
    "**Using Fulcrum Genomics' `fqgrep` to search for a match to the query sequence among the reads.**\n",
    "\n",
    "\n",
    "First use fqgrep to quickly look and see if can locate reads with the match. (See [my fqgrep-binder](https://github.com/fomightez/fqgrep-binder) for more details about Fulcrum Genomics' `fqgrep`, including a launchable demonstration notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@\u001b[38;5;30mSRR23849628.5083175\u001b[0m\n",
      "\u001b[38;5;240mTACGTATTGCTAAGCAGTGGTATCAACGCAGAGTGAATTTTTGCAAAAAACAGATCCTAAGGACCCTGCAAATTATATTCTTCATGCAGTCCTGGTTCATAGTGGAGATAATCATGGTGGACATTATGTGGTTTATCTAAACCCCAAAGGGGATGGCAAATGGTGTAAATTTGATGACGACGTGGTGTCAAGGTGTACTAAAGAGGAAGCAATTGAGCACAATTATGGGGGTCACGATGACGACCTGTCTGTTCGACACTGCACTAATGCTTACATGTTAGTCTACATCAGGGAATCAAAACTGAGTGAAGTTTTACAGGCGGTCACCGACCATGATATTCCTCAGCAGTTGGTGGAGCGATTACAAGAAGAGAAAAGGATCGAGGCTCAGAAGCGGAAGGAGCGGCAGGAAGCCCATCTCTATATGCAAGTGCAGATAGTCGCAGAGGACCAGTTTTGTGGCCACCAAGGGAATGACATGTACGATGAAGAAAAAGTGAAATACACTGTGTTCAAAGTATTGAAGAACTCCTCGCTTGCTGAGTTTGTTCAGAGCCTCTCTCAGACCATGGGATTTCCACAAGATCAAATTCGATTGTGGCCCATGCAAGCAAGGAGTAATGGAACAAAACGACCAGCAATGTTAGATAATGAAGCCGAC\u001b[0m\u001b[31mGGCAATAAAACAGTAAATATTGTTAATAGCG\u001b[0m\u001b[38;5;240mTATCTGGTTTGGAACCGTGCAGAAGGCGTTAGTCCTCTGCACTTAGTGCAGCTTGTTTCCCTTTTGGTCCACTTAACTAGAATTGGACGTTTTCTTCAATACTTGACTGTAGTTTTTCGCTCTGTCACCTAAGCCATTAGACTCTTCTAAAATCAGCGTCTCTTTTGGAAAATAGATGATTGAGCTCAGTGATAATGAAAACCCTTGGACAATATTCCTGGAAACAGTTGATCCCAGCTGGCTGCTAGTGGAGCGACCTTACCCAAGTTTGATAAAGATCGTAAGTGCCCACTGATACGCCTGCCTGCACTTAGAGCAGTAGCGTTGGATTCCTGGATTGTTGTTCTAAACACACAGGGTTAAGCCTTCTTCCCTTGCAGAAAGATGTGTTGATCAATTCCACAAAAGCTCACTAGACTTCCTGATGAAGTCAAATAAGACTGACTTGGCTGCGAGTTTCCTGTGAGGCCCGGAGACAGTAGCAGCCACGTGGGGCCGTCCTGTTCTGTCTTCAGTCTCAGCTGCTGTGCTGTGCTAATCACGTTGGTCAGATCCTAAGAGCAGGGTTGCAAACGTTGTCTGTCAGGGACCACATAGGCAATATCTCAGGCGTTTCAGGCCTTTCTGTCTGTACTAAGGCGGCCACAAAGACTATATAAATGAACGAGCTGGCTGTCTTCCAGTACAACTTTATCGACAAAACAGGTGGATCGGAATTTGCTGACCCTTGCTATAAAATGACAGACTTTTATTGCTGTGAGCTGGGCCACTTTGGCAAAGACACAAGACCATGCGCAATCTTCCCGTGGCAACGCTCTTCCAGCCAGTCAGTCCAGGTCTCAGAACTAGGAATTCTAAGTTTGCTGCACTCAGTACCGTCTTGACTGTCTAAATGTAGTGGGTTTCCATGGGTCTGATGTTTGGAAACTCAGCGGTAATAGCCTCAGCTTCGTGAATAAGCCACATCTGAAGTAACTTTTAGGTACCTTAAGCTGTCATTTCACTTGTCATTGAGCTATTCAGCTTACTTTTTTTTTTTTTGTTTTTTTGTTTGTTTGTTTTTTTGTTTTTTAAGCATTGTGCTGAGTGTTTGGATCTGCAACAAAACTTGTTTATTAACCTTGTAGATGATGTAATGTTATTTTTGAAGATGTATGATCCCAAAACGCGGAGCTTGAATTACTGTGGGCATATCTACACACCAATATCCTGTAAAATACGTAAGTCCTTCGTGCACTTACCTTCTGAGTAGATTTTGCTCAGTACATTACAGCTACACATTTAAAATATCTTCTTTCTCCTAGGTGACTTGCTCCCAGTTATGTGTGACAGAGCAGGATTTATTCAAGATACTAGCCTTATCCTCTATGAGGTTTGGACGGTTTATTTTTCCATAATTAGTATATTCTTAGTAGTTTGTGGAGGGTTTTGTTTGTCTATTTTACAGTTTGTTAGAGTGTTAGGTCTACCAGCTAACTCAGGGCCTCAGATGATCTTGAGAATGACATATTTAGATTTGTGAATTTTTTTTTTTACCTGTTGTAGAATCAAATCTGATTGTTACATATTTGTGGATTTATTCATTTAGCTTTTCCTGTTAACATTTTAACTTAAAAGGTGGATAGAATTGGGTGTAGAGAAAATACTTAAGTACATGGAAGACTATCTGGCCATATTAAACGTTAGACAAACTTGCAGTGTAACAATTTTATATCTTTCACTGTAGGAAGTTAAACCAAAAAAAAAAAAAAAAAAAAAAGAACTGTTAGCCTGAAAGATGGCTCTCTAGATTGGAGAGAGCGTCGTGTAGAGCAATACGTAACTGAACGAGTAGGTTACACAACA\u001b[0m\n",
      "+\n",
      "\u001b[38;5;240m%$$'%%')%###$$&($$')-..,,''''(+,-8;3112@:5440...7{5-,))((**(**/::<=>AAD@7666@=>@AB@>@83310257;>>>=??AEEGLTIC=89:=AE>===@A?ADDFDEGDFCBDJLEJ{JEBBB??>=>=>1'&&&(1///<=:666;EGHEFAB??BBCA@CDB@AADBDCBB@ACBK@==@FBAA?CBA@A?===?BBBBBCE?>;:9:ANMJGIHFGILICBB>@@AC<;@LIC@@ABDD?A@ADCDD<888ADGCBB@EDEEFEFDGBAA@DCDBC?>93222@?;678CJJIL{KIIFGECBCA@@?@@AGGECBD@@BCC?>>A@A@>@@;;;;8778=??@@ACCBAABBC?;=2+/*))+5/(''(30/0'&#$((*,.('('(.8>?ACE<::;=@ABCFB?>?>??ABDDBDGF<<==CEDEDA@DLMKG5436+(((0?BGC@??AD>7778=>@B@=<;=;;=@CDE@CHGNINGDEAEFEEFEECBCC{I@>?=;;:?A??@@FGE:::;0-+(({251KNEEEELK{OQMNLHFDGBBAA?AABDBCBDI<;;;DB@ONJGDCCEGDFEBA??BAAABE=:::@?==@A@;::;>==A?<99<@DFFEA??AA{B94344BB>>==C\u001b[0m\u001b[38;5;22mCDFFFG{KKCC@?>=86567=OQ?>?>:888\u001b[0m\u001b[38;5;240m@?@@>>>99HMHIFMDEE??==AA@A??@?EJFAA@AIIFGJDHDB>?EFE=0*''&'-,-89FB:??..8<??ACEE=>==ENJ{J;;>FEIIMD?@DA8887<<BDA@85+)*-0BMKMJGFIHAA@?@@<9:89673((>DDFBACBEBBBAE=GCBA=>>>BE?==?;;;=EQMJIFAAA@DFEEEG?>==BACEFL<988>ABCDB@?>?@AEC@<;<00/09BD???@GFFGJ=<;;=@@@<=?G@?;::;<;=ABPIDDCCDFFFI<=964469;;;=>>?BBEGLNKGABA998B:@>>EOHIN:87:77>67;?A@A@C==CACCA<983/149>CDCC333>?C@@??<:88:AABBBDDEJFGFIIJG@((()973111150.,06>>BAEGJ{{PSHAAB?@@I<ROL{LMHJHDBA?ACBDB><5,+/+257?3>===@FIMFC;99:BJKJGHICCACE@?BFGECDC>>=><:777=@@DEECC{G@ABBHOGFCBA9777:D<<<<<000<8556GJ=;;>+++7533377578FIHHDA====CDDCF8888=;842019:<>??DKJEC?=@@@>>:;B->@CEBBAABAABA===?CGECDDFEDBGMI??EDEG<8888778G><;800;5677:?>><>?C9888@A=>100.003?>><8668??@ACJ>>CCDHIBB;;:<CEEHFLGOFGIHM@10029HF@9:?>>=;:ADFBCDFHDEECC---.FFDEGJHFEIGDCAC{FDFFFPLGGGGFFC@AEDDFACDDC@DA?=>@BF{{KEILGKLAFCBAA@A{G{BBFF{HDGECBABBBEDDEEKIVHJGIGFCCCE@?>)))(&&&<<;6667CE?>>CJKME?BFHGI{D1001AEDFC8778ADCCCAACHID;;325,,-?>@BBADCBE::3)*++/,-++*+,,3;>CDEFEJEFFFEEDHEDDB=<<=@BBBDGBA@2228:@<<=GHC{JA>>>CFPK{J87889@AA??ABFFD???>CA?@AD@???DAABGB=986-)(())))---75>?EBBMSF>==?CCDHLIHEDFHIC@,+++199=DGBBDKMHHGJFC@AAEEGJEBABAED=;=9768@@<;<>AAAADEBBDBDEKGDB@@ABI{B>>>@DEHLKHIFHFEHD1//0DP{RGGGHDCCD@@>?;888@??=>?@MJOGHBA??ACACGKO?<86;9BLHAAA>@AGA@?@CEFCCDCAI{655/.,))).)=>>JKHMDBBEIA{HEBCBAAAC=<8D@{EBC@@ABDNNKHHHIHEEGFHGFB+*14955459212=C@@?B:FKKJOHFFGDDFFCBBBCC{J{OGE=?{B??AGGGJIGHGIKB>B@?DACC@BAC665:<=<<CDCDDBCAA??BCCDD@??<=@AHMULOIHIG{CBHDBB?<<;?@N;CBDA@B;B:3///514F;;=?>@CIBADVJDBOTF?BKCDCEB8622,.-/FGEIEFCFCDEOAD@>?>?CA@B@??@F{HF8778ACBBJ71//.88964594431001=>A>;;;?IHCEDCDDFKFGFIEJGFJIJGHED6667{)&'(-2102+))*/..-////66>@A=JFBAFMHH{HGFDC>>>DA?=.-2.;>;64;>??FDBBB5ABAACDE88<==>DGGCB=9AA@@D@@@@DEB>2100475?83(34>5:9.((*/48=??AEHFLJA@?>><53344AB@@<8548=??A@@@A@@A>;;>=<>?FG{PPNJDGEDCBGFD:CD?=>>?8--.?B;@@AECEHG=8;BD{NPIJGEDDDB8667;@AA>==<CB?@A@EB99:1,+**\u001b[0m\n",
      "@\u001b[38;5;30mSRR23849628.535194\u001b[0m\n",
      "\u001b[38;5;240mTGTATTGCTCTACACGACGCTCTTCCGATCTCACCGACCATGATATTCCTCAGCAGTTGGTGGAGCGATTACAAAGAAGAAGAAAAGGATCGAGGCTCAGAAGCGGAAGGAGCGGCAGGAAGCCCATCTCTATATAGTCGCAGAGGACCAGTTTTGTGGCCACCAAGGGAATGACATGTACGATGAAGAAAAAGTGAAATACACTGTGTTCAAAGATATCAAGAAACCCCCTCGCTTGCTGAGTTTGTTCAGAGCCTCTCTCAGACCATGGGATTTCCACAAGATCAAATTCGATTGTGGCCCATGCAAGCAAGGAGTAATGGAACAAACGACCAGCAATGTTAGATAATGAAGCCGAC\u001b[0m\u001b[31mGGCAATAAAACAGTAAATATTGTTAATAGCG\u001b[0m\u001b[38;5;240mTATCTGGTTTGGAACCGTGCAGAAGGCGTTAGTCCTTCTGCACTTAGTGCAGCTTGTTTCCCTTTTGGTCCACTTAACTAGAATTGGACGTTTTCTTCAATACTTGACTTAGTTTTTCGCTCTGTCACCTAAGCCATTAGACTCTTCTAAAATCAGCGTCTCTTTTGGAAATAGATGATTGAGCTCAGTGATAATGAAAACCCTTGGACAATATTCCTGGAAACAGTTGATCCCGAGCTGGCTGCTAGTGGAGCGACCTTACCCAAGTTTGATAAAGATCGTAAGTGCCCACGCAGACGCCTGCCTGCACTTAGAGCAGTAGCGTTGGATTCCTGGATTGTTGTTCTAAACACACAGGGTTAAGCCTTCTTCCCTTGCAGAAAGATGTGTTGATCAATTCCACAAAAAAAAAAAAAAAAAAAAAAAGTCGGCTAAGCTGGGATTTGGCCGTTGATCGGAAGAGCGTCGTGTAGAGCAATACGTAACTGAACGAAGTAACGACAAT\u001b[0m\n",
      "+\n",
      "\u001b[38;5;240m##%$%$#$%()+,+,22>>>>GC>:::<<9:<::9:>=.++*)((4/'(++*'&,1''(:=>?@ABBA?<=<64400017:66888:>====;;;>BBEGGGAA<999:6-,+&&*+={NCEDFMKLHIBEC@=;>11004..22?IFDD@;>={{C;8>B@;B?A?AA;889<>@>==9;F@A?=>>>=@?@EJNLGEFECD>=?;87+)'&&&+9AB??>@CE('''EH-(JDM{PGK;,,->?BAKGCCCDCHFFEDEEDCEEEC?D>,,,>73,++.....,.*17585:55*())8:?GDDGIL,((49;<>>>;<=>=8778EHFELHGGHHIBCGKWBBE?=>=DIHN{MKL\u001b[0m\u001b[38;5;22mMJA@??BBEFFE?CB@@?A>@?>7---3))*\u001b[0m\u001b[38;5;240m=E=866//22001..-.(3?D<:LEE=A><<<;DDFAAIGEFEDDACCIGKHPJICCEKFDDCBAAACEDGFFCBC6412-+2(&%&11223-**1788@DEEDDBIOHHFBEDFA@>>>@FLKIAHDEAAC>@@BFFIQPLHBGAA@?A@?FCA@@HIFFHIGHDCBF?>>>DEDB5E7553:<<@:>>>=DFB@??@DDEB@@@CEEB<B633/..2/=A>A@@KLDDGQGJBA?>:996764145{><@AA@BCLIIGFCG@DEDHEHF;4011,+)))&*,%&((,())51AJKE{><<=BDDEEBB><;??EBA>,>?75533558:772344D=GEBCCFCC@>>?>=AJABBB@AABCBBBACDDG{>34FDFDBABDGB@8BCDACBDCAB>B?@@DG{?>>=<=987912247;::0,->2;C7*EEJIB=<<@?;?FGIEFCCD???BBGHGICED>?@966664344*'')?>>9666;;<<B,,,,,+++&$#\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "USP7_TSL4_RET_I = 'GGCAATAAAACAGTAAATATTGTTAATAGCG'\n",
    "!fqgrep --reverse-complement --color auto {USP7_TSL4_RET_I} supporting_tables_and_data/USP7_locus_mapped_SRX19662564_reads.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two reads have exact matches to the USP7-217 retained intron-query sequence.\n",
    "Actually no other reads seem to have anything because I checked allowing 3 mismatches in two ways:\n",
    "\n",
    "**One way I allowed mistmatches**  \n",
    "One with Indraniel Das' `fqgrep`, go [here](https://github.com/fomightez/indraniel_fqgrep-binder) to run such sessions.\n",
    "\n",
    "These were the commands there:\n",
    "\n",
    "```shell\n",
    "!fqgrep -c -p 'GGCAATAAAACAGTAAATATTGTTAATAGCG' -m 3 ./USP7_locus_mapped_SRX19662564_reads.fastq\n",
    "!fqgrep -c -p 'CGCTATTAACAATATTTACTGTTTTATTGCC' -m 3 ./USP7_locus_mapped_SRX19662564_reads.fastq\n",
    "```\n",
    "\n",
    "(note 'CGCTATTAACAATATTTACTGTTTTATTGCC' is the reverse complement of `GGCAATAAAACAGTAAATATTGTTAATAGCG` (tag `USP7_TSL4_RET_I`) that I used in that manner because in my preliminary investigations of  Indraniel Das' `fqgrep` so far I have not seen a flag to do reverse complement like both Fulcrum Genomics' `fqgrep` and PatMAtch have!!)\n",
    "\n",
    "**Second way I allowed mistmatches**  \n",
    "And, second, for sessions launched from repos that have PatMatch specified to be installed in resulting Jupyter sessions, [my patmatch-binder repo](https://github.com/fomightez/patmatch-binder) (or [my blast-binder repo](https://github.com/fomightez/blast-binder) has PatMAtch, too), checked with allowing 3 mismatches:\n",
    "\n",
    "```python\n",
    "RETI = \"GGCAATAAAACAGTAAATATTGTTAATAGCG\"\n",
    "!perl patmatch_1.2/patmatch.pl -c {RETI} demo.fasta 3 ids\n",
    "```\n",
    "\n",
    "For PatMatch use, first had to covert `USP7_locus_mapped_SRX19662564_reads.fastq` to FASTA using AWK.\n",
    "\n",
    "UPSHOT OF BOTH: still only those two with the perfect matches seen!  \n",
    "Note that I would suggest doing analyses like these with tools that allow fuzzy searching, too, when considering your own sequences and read data, especially with long read technology that can show errors. I am only focusing just on Fulcrum Genomics' fqgrep because it is easy to install and works in this case since there is a perfect match. However, you'll note I looked into that in additional, separate investigation. \n",
    "\n",
    "Let's delve into that second listed read containing the match some. Specifically the one:\n",
    "\n",
    "```text\n",
    "@SRR23849628.535194\n",
    "TGTATTGCTCTACACGACGCTCTTCCGATCTCACCGACCATGATATTCCTCAGCAGTTGGTGGAGCGATTACAAAGAAGAAGAAAAGGATCGAGGCTCAGAAGCGGAAGGAGCGGCAGGAAGCCCATCTCTATATAGTCGCAGAGGACCAGTTTTGTGGCCACCAAGGGAATGACATGTACGATGAAGAAAAAGTGAAATACACTGTGTTCAAAGATATCAAGAAACCCCCTCGCTTGCTGAGTTTGTTCAGAGCCTCTCTCAGACCATGGGATTTCCACAAGATCAAATTCGATTGTGGCCCATGCAAGCAAGGAGTAATGGAACAAACGACCAGCAATGTTAGATAATGAAGCCGACGGCAATAAAACAGTAAATATTGTTAATAGCGTATCTGGTTTGGAACCGTGCAGAAGGCGTTAGTCCTTCTGCACTTAGTGCAGCTTGTTTCCCTTTTGGTCCACTTAACTAGAATTGGACGTTTTCTTCAATACTTGACTTAGTTTTTCGCTCTGTCACCTAAGCCATTAGACTCTTCTAAAATCAGCGTCTCTTTTGGAAATAGATGATTGAGCTCAGTGATAATGAAAACCCTTGGACAATATTCCTGGAAACAGTTGATCCCGAGCTGGCTGCTAGTGGAGCGACCTTACCCAAGTTTGATAAAGATCGTAAGTGCCCACGCAGACGCCTGCCTGCACTTAGAGCAGTAGCGTTGGATTCCTGGATTGTTGTTCTAAACACACAGGGTTAAGCCTTCTTCCCTTGCAGAAAGATGTGTTGATCAATTCCACAAAAAAAAAAAAAAAAAAAAAAAGTCGGCTAAGCTGGGATTTGGCCGTTGATCGGAAGAGCGTCGTGTAGAGCAATACGTAACTGAACGAAGTAACGACAAT\n",
    "```\n",
    "\n",
    "(Note YOU HAVE TO SCROLL TO THE RIGHT TO SEE ALL OF IT. Ot doesn't wrap in the notebook automatically. I haven't decided if I should make it have lines instead?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That second one looks immediately as a possibility as it is small, in the range of the expected few hundred bps.  \n",
    "So let's start there and use BLAST to compare the entire 895 bp of it to the  567 bp USP7-217 transcript pairwise via the NCBI portal.  That gives:\n",
    "\n",
    "```text\n",
    "Query Cover 62% \n",
    "Alignment statistics for match #1\n",
    "Score\tExpect\tIdentities\tGaps\tStrand\n",
    "910 bits(1008)\t0.0\t548/572(96%)\t19/572(3%)\tPlus/Plus\n",
    "Query  56   GTTGGTGGAGCGATTACAAAGAAGAAGAAAAGGATCGAGGCTCAGAAGCGGAAGGAGCGG  115\n",
    "            ||||||||||||||||||| ||||| ||||||||||||||||||||||||||||||||||\n",
    "Sbjct  1    GTTGGTGGAGCGATTACAA-GAAGA-GAAAAGGATCGAGGCTCAGAAGCGGAAGGAGCGG  58\n",
    "\n",
    "Query  116  CAGGAAGCCCATCTCTATAT------------AGTCGCAGAGGACCAGTTTTGTGGCCAC  163\n",
    "            ||||||||||||||||||||            ||||||||||||||||||||||||||||\n",
    "Sbjct  59   CAGGAAGCCCATCTCTATATGCAAGTGCAGATAGTCGCAGAGGACCAGTTTTGTGGCCAC  118\n",
    "\n",
    "Query  164  CAAGGGAATGACATGTACGATGAAGAAAAAGTGAAATACACTGTGTTCAAAGATATCAAG  223\n",
    "            ||||||||||||||||||||||||||||||||||||||||||||||||||||   | |||\n",
    "Sbjct  119  CAAGGGAATGACATGTACGATGAAGAAAAAGTGAAATACACTGTGTTCAAAGTATTGAAG  178\n",
    "\n",
    "Query  224  AAACCCCCTCGCTTGCTGAGTTTGTTCAGAGCCTCTCTCAGACCATGGGATTTCCACAAG  283\n",
    "            ||  | ||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "Sbjct  179  AA--CTCCTCGCTTGCTGAGTTTGTTCAGAGCCTCTCTCAGACCATGGGATTTCCACAAG  236\n",
    "\n",
    "Query  284  ATCAAATTCGATTGTGGCCCATGCAAGCAAGGAGTAATGGAACAAA-CGACCAGCAATGT  342\n",
    "            |||||||||||||||||||||||||||||||||||||||||||||| |||||||||||||\n",
    "Sbjct  237  ATCAAATTCGATTGTGGCCCATGCAAGCAAGGAGTAATGGAACAAAACGACCAGCAATGT  296\n",
    "\n",
    "Query  343  TAGATAATGAAGCCGACGGCAATAAAACAGTAAATATTGTTAATAGCGTATCTGGTTTGG  402\n",
    "            ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "Sbjct  297  TAGATAATGAAGCCGACGGCAATAAAACAGTAAATATTGTTAATAGCGTATCTGGTTTGG  356\n",
    "\n",
    "Query  403  AACCGTGCAGAAGGCGTTAGTCCTTCTGCACTTAGTGCAGCTTGTTTCCCTTTTGGTCCA  462\n",
    "            |||||||||||||||||||||||| |||||||||||||||||||||||||||||||||||\n",
    "Sbjct  357  AACCGTGCAGAAGGCGTTAGTCCT-CTGCACTTAGTGCAGCTTGTTTCCCTTTTGGTCCA  415\n",
    "\n",
    "Query  463  CTTAACTAGAATTGGACGTTTTCTTCAATACTTGACT-TAGTTTTTCGCTCTGTCACCTA  521\n",
    "            ||||||||||||||||||||||||||||||||||||| ||||||||||||||||||||||\n",
    "Sbjct  416  CTTAACTAGAATTGGACGTTTTCTTCAATACTTGACTGTAGTTTTTCGCTCTGTCACCTA  475\n",
    "\n",
    "Query  522  AGCCATTAGACTCTTCTAAAATCAGCGTCTCTTTTGGAAATAGATGATTGAGCTCAGTGA  581\n",
    "            ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "Sbjct  476  AGCCATTAGACTCTTCTAAAATCAGCGTCTCTTTTGGAAATAGATGATTGAGCTCAGTGA  535\n",
    "\n",
    "Query  582  TAATGAAAACCCTTGGACAATATTCCTGGAAA  613\n",
    "            ||||||||||||||||||||||||||||||||\n",
    "Sbjct  536  TAATGAAAACCCTTGGACAATATTCCTGGAAA  567\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That read is continguous and well matching to the 567 bp of USP7-217 transcript over a large span that includes two splice junctions, plus importantly the lack of a junction where the retained intron continues to make of the transcript (around the 300 bp point of the USP7-217 transcript on the bottom in the alignment), and so it seems **that read is indeed an example of the TSL4-rated transcript ENST00000567329 (USP7-217)**.\n",
    "\n",
    "That explains the central 567 bps of the read. In looking into what the rest of the 895 bps is I realized what I Ensembl gave me when I clicked 'Download' for the ENST00000567329 (USP7-217) 'cDNA' only included part of the content you'll see if you go to [here](https://useast.ensembl.org/Homo_sapiens/Transcript/Exons?db=core;g=ENSG00000187555;r=16:8895045-8956380;t=ENST00000567329) and toggle the 'Exons' view using the navigation panel in the upper, side left of the page. Specifically it starts with `GTTGGTGGAGCGATTACAAGA...` and ends with `...AACCCTTGGACAATATTCCTGGAAA` and that 567 bp sequence Ensembl gives leaves off the part the page shows as `5' upstream sequence` (`.........cctgcaggtgaagttttacaggcggtcaccgaccatgatattcctcagca`) and `3' downstream sequence` (`cagttgatcccgagctggctgctagtggagcgaccttacccaagtttgat.........`). So the `5' upstream sequence` explains the first 55 bps. You can even see the match to what I included above that I copied and pasted from the Ensmbl page. Below on the top is from Enxmbl and on the bottom is the start of the `@SRR23849628.535194` read, the 55bps before the part shown in the BLAST result above:  \n",
    "\n",
    "```text\n",
    "cctgcaggtgaa--gttttacaggcgg-----------tcaccgaccatgatattcctcagca\n",
    "        ||.|  |.|.||||.|..|           |||||||||||||||||||||||||\n",
    "--------TGTATTGCTCTACACGACGCTCTTCCGATCTCACCGACCATGATATTCCTCAGCA\n",
    "```\n",
    "\n",
    "The extreme left end may be adapter/technical sequence, but the main part is clearly a match between what Ensembl indicates as `5' upstream sequence` and the read data.\n",
    "\n",
    "It is a similar thing for the 3' end. In fact, you probably already noted the Poly(A) tail being clearly defined towards the end of the read @SRR23849628.535194 shown earlier. And what is between the 614th nucleotide of the read and there matches nicely to the `3' downstream sequence`. Here shows on the top what Esembl has for the start of `3' downstream sequence` with the read part after the BLAST pairwise alignment shown on the bottom:\n",
    "\n",
    "```text\n",
    "cagttgatcccgagctggctgctagtggagcgaccttacccaagtttgat.........\n",
    "CAGTTGATCCCGAGCTGGCTGCTAGTGGAGCGACCTTACCCAAGTTTGATAAAGATCGTAAGTGCCCACGCAGACGCCTGCCTGCACTTAGAGCAGTAGCGTTGGATTCCTGGATTGTTGTTCTAAACACACAGGGTTAAGCCTTCTTCCCTTGCAGAAAGATGTGTTGATCAATTCCACAAAAAAAAAAAAAAAAAAAAAAA\n",
    "```\n",
    "\n",
    "That matches really well. And in fact what Ensembl represents with `.........` also matches very well as can bee see by taking more of the downstream part of that region of USP7 and aligning with [EMBOSS Needle - pairwise sequence alignment](https://www.ebi.ac.uk/jdispatcher/psa/emboss_needle?stype=dna&matrix=EDNAFULL):\n",
    "\n",
    "```text\n",
    "USP73p_001         1 CAGTTGATCCCGAGCTGGCTGCTAGTGGAGCGACCTTACCCAAGTTTGAT     50\n",
    "                     ||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "535194_001         1 CAGTTGATCCCGAGCTGGCTGCTAGTGGAGCGACCTTACCCAAGTTTGAT     50\n",
    "\n",
    "USP73p_001        51 AAAGATCGTAAGTGCCCACG-AGACGCCTGCCTGCACTTAGAGCAGTAGC     99\n",
    "                     |||||||||||||||||||| |||||||||||||||||||||||||||||\n",
    "535194_001        51 AAAGATCGTAAGTGCCCACGCAGACGCCTGCCTGCACTTAGAGCAGTAGC    100\n",
    "\n",
    "USP73p_001       100 GTTGGATTCCTGGATTGTTGTTCTAAACACACAGGGTTAAGCCTTCTTCC    149\n",
    "                     ||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "535194_001       101 GTTGGATTCCTGGATTGTTGTTCTAAACACACAGGGTTAAGCCTTCTTCC    150\n",
    "\n",
    "USP73p_001       150 CTTGCAGAAAGATGTGTTGATCAATTCCACAAAA----------------    183\n",
    "                     ||||||||||||||||||||||||||||||||||                \n",
    "535194_001       151 CTTGCAGAAAGATGTGTTGATCAATTCCACAAAAAAAAAAAAAAAAAAAA    200\n",
    "\n",
    "USP73p_001       184 ---    183\n",
    "                        \n",
    "535194_001       201 AAA    203\n",
    "```\n",
    "\n",
    "This features the the Poly(A) tail at the end of that nice match with the USP7-217 `3' downstream sequence`.\n",
    "\n",
    "As for the part after the Poly(A) tail, that looks to mainly be adapter sequences, or something technical and not biological, because the main portion of it, `CGTTGATCGGAAGAGCGTCGTGTAGAGCAATACGTAACTGAA`, occurs a lot in the reads. Specifically, the Jupyter notebook [checking 3' end read_SRR23849628.535194 for adapter](checking_3prime_end_read_SRR23849628.535194_for_adapter.ipynb), shows it, or something close to it occurs, in 362 out of the 863 reads. And that wasn't even being thorough in looking into it.\n",
    "\n",
    "So that accounts for the entire 895 bps of the read and contribures to the case supporting it being an instance of of the TSL4-rated transcript ENST00000567329 (USP7-217). This speaks to the power of Logan Search to help find things that may be rare.\n",
    "\n",
    "With the features of that informative read dissected, let's consider it in more context.\n",
    "\n",
    "**You may be saying but there was another read `fqgrep` identified...**\n",
    "\n",
    "What about the other read `fqgrep` helped indicate has a match to the \"retained intron\" query sequence?  \n",
    "At first glance it seems interesting that the other read is an even better match over the same 567 bp span:\n",
    "\n",
    "```text\n",
    "Alignment statistics for match #1\n",
    "Score\tExpect\tIdentities\tGaps\tStrand\n",
    "1017 bits(1127)\t0.0\t567/568(99%)\t1/568(0%)\tPlus/Plus\n",
    "Query  349  GTTGGTGGAGCGATTACAAGAAGAGAAAAGGATCGAGGCTCAGAAGCGGAAGGAGCGGCA  408\n",
    "            ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "Sbjct  1    GTTGGTGGAGCGATTACAAGAAGAGAAAAGGATCGAGGCTCAGAAGCGGAAGGAGCGGCA  60\n",
    "\n",
    "Query  409  GGAAGCCCATCTCTATATGCAAGTGCAGATAGTCGCAGAGGACCAGTTTTGTGGCCACCA  468\n",
    "            ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "Sbjct  61   GGAAGCCCATCTCTATATGCAAGTGCAGATAGTCGCAGAGGACCAGTTTTGTGGCCACCA  120\n",
    "\n",
    "Query  469  AGGGAATGACATGTACGATGAAGAAAAAGTGAAATACACTGTGTTCAAAGTATTGAAGAA  528\n",
    "            ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "Sbjct  121  AGGGAATGACATGTACGATGAAGAAAAAGTGAAATACACTGTGTTCAAAGTATTGAAGAA  180\n",
    "\n",
    "Query  529  CTCCTCGCTTGCTGAGTTTGTTCAGAGCCTCTCTCAGACCATGGGATTTCCACAAGATCA  588\n",
    "            ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "Sbjct  181  CTCCTCGCTTGCTGAGTTTGTTCAGAGCCTCTCTCAGACCATGGGATTTCCACAAGATCA  240\n",
    "\n",
    "Query  589  AATTCGATTGTGGCCCATGCAAGCAAGGAGTAATGGAACAAAACGACCAGCAATGTTAGA  648\n",
    "            ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "Sbjct  241  AATTCGATTGTGGCCCATGCAAGCAAGGAGTAATGGAACAAAACGACCAGCAATGTTAGA  300\n",
    "\n",
    "Query  649  TAATGAAGCCGACGGCAATAAAACAGTAAATATTGTTAATAGCGTATCTGGTTTGGAACC  708\n",
    "            ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "Sbjct  301  TAATGAAGCCGACGGCAATAAAACAGTAAATATTGTTAATAGCGTATCTGGTTTGGAACC  360\n",
    "\n",
    "Query  709  GTGCAGAAGGCGTTAGTCCTCTGCACTTAGTGCAGCTTGTTTCCCTTTTGGTCCACTTAA  768\n",
    "            ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "Sbjct  361  GTGCAGAAGGCGTTAGTCCTCTGCACTTAGTGCAGCTTGTTTCCCTTTTGGTCCACTTAA  420\n",
    "\n",
    "Query  769  CTAGAATTGGACGTTTTCTTCAATACTTGACTGTAGTTTTTCGCTCTGTCACCTAAGCCA  828\n",
    "            ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "Sbjct  421  CTAGAATTGGACGTTTTCTTCAATACTTGACTGTAGTTTTTCGCTCTGTCACCTAAGCCA  480\n",
    "\n",
    "Query  829  TTAGACTCTTCTAAAATCAGCGTCTCTTTTGGAAAATAGATGATTGAGCTCAGTGATAAT  888\n",
    "            |||||||||||||||||||||||||||||||| |||||||||||||||||||||||||||\n",
    "Sbjct  481  TTAGACTCTTCTAAAATCAGCGTCTCTTTTGG-AAATAGATGATTGAGCTCAGTGATAAT  539\n",
    "\n",
    "Query  889  GAAAACCCTTGGACAATATTCCTGGAAA  916\n",
    "            ||||||||||||||||||||||||||||\n",
    "Sbjct  540  GAAAACCCTTGGACAATATTCCTGGAAA  567\n",
    "```\n",
    "\n",
    "However, it is larger than expected for USP7-217 and matches other parts of the unspliced USP7 gene as well, and so it may indeed be represenative of an unspliced transcript, or more likely, the result of contaminating DNA being sequenced.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all very insightful but there's 863 reads in `USP7_locus_mapped_SRX19662564_reads.fastq`. Can we scale the process of such analysis?\n",
    "\n",
    "The rest of the notebook will be comprised of doing a rough sketch of that to classify the additional 861 reads in `USP7_locus_mapped_SRX19662564_reads.fastq`. Though we already have preliminary evidence from searching for the query pattern and biological variations of it, that it doesn't occur elsewhere, it would be nice to have independent evidence of that by looking at each sequence and considering it further with BLAST. USP7 has a lot of transcripts so we won't thoroughly classify all of them here, but we'll look for candidates that seem to stronly match the canonical USP7 (MANE) transcript, and look via alignment for any that, though they don't have a good match to the query sequence, may indicate a godd match to the TSL4-rated transcript ENST00000567329 (USP7-217) that retains the intron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "#### Combine in the result of examining for query sequence with BLAST to identify transcripts\n",
    "\n",
    "Run the next cell to make databases based on the sequences of the transcripts, both the MANE Select one and the USP9-217 one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 04/17/2025 20:14:37\n",
      "New DB name:   /home/jovyan/supporting_tables_and_data/Homo_sapiens_ENST00000344836_9_sequence_USP7-MANE_trancript.fasta\n",
      "New DB title:  supporting_tables_and_data/Homo_sapiens_ENST00000344836_9_sequence_USP7-MANE_trancript.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/jovyan/supporting_tables_and_data/Homo_sapiens_ENST00000344836_9_sequence_USP7-MANE_trancript.fasta\n",
      "Keep MBits: T\n",
      "Maximum file size: 3000000000B\n",
      "Adding sequences from FASTA; added 1 sequences in 0.000257015 seconds.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building a new DB, current time: 04/17/2025 20:14:38\n",
      "New DB name:   /home/jovyan/supporting_tables_and_data/Homo_sapiens_ENST00000567329_1_sequence_USP7-217_trancript.fasta\n",
      "New DB title:  supporting_tables_and_data/Homo_sapiens_ENST00000567329_1_sequence_USP7-217_trancript.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/jovyan/supporting_tables_and_data/Homo_sapiens_ENST00000567329_1_sequence_USP7-217_trancript.fasta\n",
      "Keep MBits: T\n",
      "Maximum file size: 3000000000B\n",
      "Adding sequences from FASTA; added 1 sequences in 0.000232935 seconds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!makeblastdb -in supporting_tables_and_data/Homo_sapiens_ENST00000344836_9_sequence_USP7-MANE_trancript.fasta -dbtype nucl\n",
    "!makeblastdb -in supporting_tables_and_data/Homo_sapiens_ENST00000567329_1_sequence_USP7-217_trancript.fasta  -dbtype nucl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set to iterate on reads with BLAST query against each of the transcript options being screened for here. But also want to check for query sequence so know which ones have it and can use that in the programmatic screen.  \n",
    "This is code towards doing that check for the query sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screened reads for presence of match to `USP7_TSL4_RET_I` sequence:\n",
      "Found: ['SRR23849628.5083175', 'SRR23849628.535194']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def parse_fqgrep_output_string_for_identitiers(fqgrep_output):\n",
    "    \"\"\"\n",
    "    Parse fqgrep output string and extract the description lines (headers) from FASTQ sequences.\n",
    "    \n",
    "    Args:\n",
    "        fqgrep_output: String containing fqgrep output\n",
    "        \n",
    "    Returns:\n",
    "        A list of description lines.\n",
    "    \"\"\"\n",
    "    # Pattern to match FASTQ header lines, which start with '@'\n",
    "    # and are typically followed by a sequence identifier\n",
    "    pattern = r'^@\\S+$'\n",
    "    # Find all matches in the content, using multiline mode\n",
    "    description_lines = re.findall(pattern, fqgrep_output, re.MULTILINE)\n",
    "    return description_lines\n",
    "\n",
    "USP7_TSL4_RET_I = 'GGCAATAAAACAGTAAATATTGTTAATAGCG'\n",
    "o = !fqgrep --reverse-complement --color auto {USP7_TSL4_RET_I} supporting_tables_and_data/USP7_locus_mapped_SRX19662564_reads.fastq\n",
    "identifiers_from_reads_with_matches = parse_fqgrep_output_string_for_identitiers(o.n)\n",
    "identifiers_from_reads_with_matches_without_ampersand = [x[1:]for x in identifiers_from_reads_with_matches]\n",
    "#print(identifiers_from_reads_with_matches) # Uncomment for debugging\n",
    "print(f\"Screened reads for presence of match to `USP7_TSL4_RET_I` sequence:\\nFound: {identifiers_from_reads_with_matches_without_ampersand}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will actually iterate running the two BLAST jobs on each read to prepare for subsequenct classifying, it will take like 5 to 10 minutes to run the roughly 1700 BLAST comparisons (BE PATIENT!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# ABOVE LINE to suppress a long stream of output as each sequence/ dataframe is processed\n",
    "import os\n",
    "from blast_to_df import blast_to_df\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_fastq_to_individual_fastas_and_thenBLAST(fastq_file, output_dir=\".\"):\n",
    "    \"\"\"\n",
    "    Convert each read in a FASTQ file to an individual FASTA file,\n",
    "    then some BLAST queries on each FASTA file to see what it matches \n",
    "    best out of the two transcripts. Or if matches well to neither.\n",
    "\n",
    "    Save results in a list of two-entry tuples for now with each tuple \n",
    "    is the dataframe of results.\n",
    "    \n",
    "    Args:\n",
    "        fastq_file (str): Path to input FASTQ file\n",
    "        output_dir (str): Directory where to save individual FASTA files\n",
    "    \"\"\"\n",
    "    max_reads=1800 # set low for development; set impossibly high for typical runs\n",
    "\n",
    "    df_pairs_plus_fastafile = []\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    with open(fastq_file, 'r') as fin:\n",
    "        read_count = 0\n",
    "        header = \"\"\n",
    "        sequence = \"\"\n",
    "        \n",
    "        line_count = 0\n",
    "        for line in fin:\n",
    "            line = line.strip()\n",
    "            line_count += 1\n",
    "            mod = line_count % 4\n",
    "            \n",
    "            if mod == 1:  # Header line (starts with @)\n",
    "                header = line[1:]  # Remove the '@' character\n",
    "                read_count += 1\n",
    "            elif mod == 2:  # Sequence line\n",
    "                sequence = line\n",
    "            elif mod == 0:  # Quality line (fourth line) - we've completed a read\n",
    "                # Create individual FASTA file\n",
    "                fasta_file = os.path.join(output_dir, f\"{header}.fasta\")\n",
    "                \n",
    "                with open(fasta_file, 'w') as fout:\n",
    "                    fout.write(f\">{header}\\n{sequence}\\n\")\n",
    "                \n",
    "                # Now that the FASTA file exists, you can act on it\n",
    "                results_tuple = process_individual_fasta_via_BLAST(fasta_file)\n",
    "                # FOR DEVELOPMENT ONLY\" check each has returned something. I was originally\n",
    "                # planning to add a 'placeholder' / indicator for those not returning anything\n",
    "                # good or dataframe without rows, but decided easy enough to keep checking for\n",
    "                # later since would need to check for status either way,\n",
    "                print(isinstance(results_tuple[0], pd.DataFrame) and len(results_tuple[0]) > 0) # Uncomment for development\n",
    "                print(isinstance(results_tuple[1], pd.DataFrame)  and len(results_tuple[1]) > 0) # Uncomment for development\n",
    "                \n",
    "                df_pairs_plus_fastafile.append((results_tuple[0],results_tuple[1],fasta_file))\n",
    "                              \n",
    "        \n",
    "\n",
    "                # Break after processing max_reads\n",
    "                if read_count >= max_reads:\n",
    "                    print(f\"Reached maximum number of reads ({max_reads}). Stopping.\")\n",
    "                    break\n",
    "    return df_pairs_plus_fastafile\n",
    "\n",
    "import re\n",
    "def parse_fqgrep_output_string_for_identitiers(fqgrep_output):\n",
    "    \"\"\"\n",
    "    Parse fqgrep output string and extract the description lines (headers) from FASTQ sequences.\n",
    "    \n",
    "    Args:\n",
    "        fqgrep_output: String containing fqgrep output\n",
    "        \n",
    "    Returns:\n",
    "        A list of description lines.\n",
    "    \"\"\"\n",
    "    # Pattern to match FASTQ header lines, which start with '@'\n",
    "    # and are typically followed by a sequence identifier\n",
    "    pattern = r'^@\\S+$'\n",
    "    # Find all matches in the content, using multiline mode\n",
    "    description_lines = re.findall(pattern, fqgrep_output, re.MULTILINE)\n",
    "    return description_lines\n",
    "\n",
    "# as preparation for classification, also collect identifiers that have matches\n",
    "# to the query sequence.\n",
    "USP7_TSL4_RET_I = 'GGCAATAAAACAGTAAATATTGTTAATAGCG'\n",
    "o = !fqgrep --reverse-complement --color auto {USP7_TSL4_RET_I} supporting_tables_and_data/USP7_locus_mapped_SRX19662564_reads.fastq\n",
    "identifiers_from_reads_with_matches = parse_fqgrep_output_string_for_identitiers(o.n)\n",
    "identifiers_from_reads_with_matches_without_ampersand = [x[1:]for x in identifiers_from_reads_with_matches]\n",
    "\n",
    "def process_individual_fasta_via_BLAST(fasta_file):\n",
    "    \"\"\"\n",
    "    Process an individual FASTA file to use BLAST to determine\n",
    "    if matches MANE transcript or USP7-217 best.\n",
    "    Return the dataframe pairs plus the FASTA file used in a \n",
    "    three member tuple\n",
    "    \n",
    "    Args:\n",
    "        fasta_file (str): Path to FASTA file\n",
    "    \"\"\"\n",
    "    print(f\"Determining via BLAST best match: {fasta_file}\")\n",
    "    mane_result = !blastn -query {fasta_file} -db supporting_tables_and_data/Homo_sapiens_ENST00000344836_9_sequence_USP7-MANE_trancript.fasta -outfmt \"6 qseqid sseqid stitle pident qcovs length mismatch gapopen qstart qend sstart send qframe sframe frames evalue bitscore qseq sseq\" -task blastn\n",
    "    the_217_result = !blastn -query {fasta_file} -db supporting_tables_and_data/Homo_sapiens_ENST00000567329_1_sequence_USP7-217_trancript.fasta  -outfmt \"6 qseqid sseqid stitle pident qcovs length mismatch gapopen qstart qend sstart send qframe sframe frames evalue bitscore qseq sseq\" -task blastn\n",
    "    df_mane = blast_to_df(mane_result.n)\n",
    "    df_217 = blast_to_df(the_217_result.n)\n",
    "    #blast_df.head() # ONLY FOR DEBUGGING IN DEVELOPMENT\n",
    "    \n",
    "    # Process the newly made FASTA file\n",
    "    # return the tuple of dfs\n",
    "    return (df_mane,df_217)\n",
    "\n",
    "# Example usage\n",
    "#process_fastq_to_individual_fastas(\"input.fastq\", \"output_fastas\")\n",
    "blast_df_pairs_plus_file = process_fastq_to_individual_fastas_and_thenBLAST(\"supporting_tables_and_data/USP7_locus_mapped_SRX19662564_reads.fastq\", \"converted.fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the actual classification step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# classify each as match two either transcript or neither, \n",
    "# the ouput will be a four member tuple: \n",
    "#       -the max BLAST result\n",
    "#       - the classification\n",
    "#       - FASTA file\n",
    "#       - length of query sequence\n",
    "# Additional logic:\n",
    "# if it has the RET_I 31-mer sequence it is going to get considered as \n",
    "# TSL4-rated USP-217 transcript version, as preliminary efforts covered\n",
    "# above spelled that out. \n",
    "# Calling dataframes that have no values causes key errors, so there is a\n",
    "# lot of checks early on that each dataframe, returned from BLAST search \n",
    "# against each of the two sequences, has content.\n",
    "# This is only meant AS SIMPLE APPROXIMATION AT THIS TIME.\n",
    "import os\n",
    "from pyfaidx import Fasta\n",
    "output_dir = \"converted.fasta\"\n",
    "transcript_length = 567 #length of ENST00000567329 (USP7-217)\n",
    "\n",
    "def get_fasta_sequence_length(fasta_file):\n",
    "    \"\"\"\n",
    "    Get the length of a sequence in a FASTA file using pyfaidx.\n",
    "    Assumes the FASTA file contains a single sequence.\n",
    "    \"\"\"\n",
    "    sequence = Fasta(fasta_file)\n",
    "    # Get the first (and only) sequence key\n",
    "    first_sequence_key = list(sequence.keys())[0]\n",
    "    sequence_length = len(sequence[first_sequence_key])\n",
    "    return sequence_length\n",
    "def check_if_matches_identified_sequences(FASTAfile_identifier):\n",
    "    #identifier_from_FASTA_path = os.path.splitext(os.path.basename(FASTAfile_path))[0] #drop directory and `.fasta` extension\n",
    "    # moved above conversion to main process calling this so could use in data collection\n",
    "    print(FASTAfile_identifier)\n",
    "    return FASTAfile_identifier in identifiers_from_reads_with_matches_without_ampersand\n",
    "\n",
    "def classify_pair(df1,df2,FASTAfile):\n",
    "    print(FASTAfile)\n",
    "    fa_seq_length = get_fasta_sequence_length(FASTAfile)\n",
    "    FASTAfile_identifier = os.path.splitext(os.path.basename(FASTAfile))[0] #drop directory and `.fasta` extension\n",
    "    print(FASTAfile_identifier)\n",
    "    print(f\"{len(df1)} rows for MANE_df\")\n",
    "    print(f\"{len(df2)} rows for Two17_df\")\n",
    "    \n",
    "    current_sequence_contains_match_to_query_sequence = check_if_matches_identified_sequences(FASTAfile_identifier)\n",
    "\n",
    "    # first make sure something reasonable.\n",
    "    # Otherwise return 'neither'\n",
    "    if not len(df1) > 0 and not len(df2) > 0:\n",
    "        return 0,'neither',FASTAfile_identifier,fa_seq_length\n",
    "    if len(df1) > 0:\n",
    "        mane_length = df1.length[0]\n",
    "        print(f\"{mane_length} : MANE_df length column\")\n",
    "        if mane_length > 700 and len(df2) == 0:\n",
    "            print(FASTAfile, \"IS MANE!!!\")\n",
    "            return mane_length, \"USP-MANE\", FASTAfile_identifier,fa_seq_length\n",
    "    if len(df2) > 0:\n",
    "        two17_length = df2.length[0]\n",
    "        print(f\" {two17_length} : Two17_df length column\")\n",
    "    else:\n",
    "        print(\"No content for Two17_df\")\n",
    "        two17_length = 0\n",
    "        if mane_length > 300 and len(df2) == 0 and df1.qcovs[0] > 39:\n",
    "            print(FASTAfile, \"if Likely MANE!\")\n",
    "            return mane_length, \"USP-MANE\", FASTAfile_identifier,fa_seq_length\n",
    "    print(f\"{df1.qcovs[0]} : %query cover\")\n",
    "    \n",
    "    # If has match the RET_I, consider it as USP-217 given preliminary\n",
    "    # results here. Unless very long and then it probably 'unspliced/\n",
    "    # genomic'.(Obviously, this may need customization if adapting to \n",
    "    # different query sequences and data.)\n",
    "    if current_sequence_contains_match_to_query_sequence:\n",
    "        if fa_seq_length < (transcript_length * 2):\n",
    "            return two17_length, \"USP-217\", FASTAfile_identifier,fa_seq_length\n",
    "        else:\n",
    "            return two17_length, \"unspliced/genomic\", FASTAfile_identifier,fa_seq_length\n",
    "    \n",
    "    # Continue to make sure something reasonable relative each other.\n",
    "    # Otherwise return 'neither'\n",
    "    if df1.qcovs[0] < 40:\n",
    "        return df1.length[0],'neither',FASTAfile_identifier,fa_seq_length\n",
    "\n",
    "    if mane_length >= two17_length:\n",
    "        return mane_length, \"USP-MANE\", FASTAfile_identifier,fa_seq_length  # First dataframe has larger or equal value\n",
    "    else:\n",
    "        # based on my searches with fuzzy version of RET_I 31-mer sequence, I don't \n",
    "        # expect there to be good matches without that but it is here in case it\n",
    "        # catches something and also to more easily set-up for adapting to different\n",
    "        # query and data.\n",
    "        return two17_length, \"USP-217\", FASTAfile_identifier,fa_seq_length  # Second dataframe has larger value for length\n",
    "    return df1.length[0],'neither',FASTAfile_identifier,fa_seq_length\n",
    "classifications_list = []        \n",
    "for mane_df,two17_df,FASTAfile in blast_df_pairs_plus_file:\n",
    "    returned_four_item_tuple = classify_pair(mane_df,two17_df, FASTAfile)\n",
    "    print(returned_four_item_tuple)\n",
    "    classifications_list.append(returned_four_item_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_hit_length</th>\n",
       "      <th>classification</th>\n",
       "      <th>read_id</th>\n",
       "      <th>read_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>neither</td>\n",
       "      <td>SRR23849628.2721367</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>neither</td>\n",
       "      <td>SRR23849628.1423419</td>\n",
       "      <td>2829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>neither</td>\n",
       "      <td>SRR23849628.3205402</td>\n",
       "      <td>1784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>neither</td>\n",
       "      <td>SRR23849628.870297</td>\n",
       "      <td>3009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>neither</td>\n",
       "      <td>SRR23849628.2788216</td>\n",
       "      <td>2288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>12</td>\n",
       "      <td>neither</td>\n",
       "      <td>SRR23849628.1331608</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>11</td>\n",
       "      <td>neither</td>\n",
       "      <td>SRR23849628.2284886</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>18</td>\n",
       "      <td>neither</td>\n",
       "      <td>SRR23849628.1243519</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0</td>\n",
       "      <td>neither</td>\n",
       "      <td>SRR23849628.524796</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>18</td>\n",
       "      <td>neither</td>\n",
       "      <td>SRR23849628.6441316</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>863 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     best_hit_length classification              read_id  read_length\n",
       "0                106        neither  SRR23849628.2721367         2012\n",
       "1                 17        neither  SRR23849628.1423419         2829\n",
       "2                 20        neither  SRR23849628.3205402         1784\n",
       "3                 16        neither   SRR23849628.870297         3009\n",
       "4                105        neither  SRR23849628.2788216         2288\n",
       "..               ...            ...                  ...          ...\n",
       "858               12        neither  SRR23849628.1331608          959\n",
       "859               11        neither  SRR23849628.2284886          924\n",
       "860               18        neither  SRR23849628.1243519         2486\n",
       "861                0        neither   SRR23849628.524796          832\n",
       "862               18        neither  SRR23849628.6441316         1220\n",
       "\n",
       "[863 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications_df = pd.DataFrame(classifications_list, columns=['best_hit_length', 'classification', 'read_id', 'read_length'])\n",
    "classifications_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all 863 classified, ready to see how the classifications break down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification\n",
      "USP-MANE             556\n",
      "neither              305\n",
      "unspliced/genomic      1\n",
      "USP-217                1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "classification_counts = classifications_df['classification'].value_counts()\n",
    "print(classification_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So ENST00000567329 (USP7-217) is like 1 to 556 of the other USP-7 transcripts.\n",
    "\n",
    "Not even quite 0.2% of all identified USP7 transcripts.  \n",
    "Probably explains in part why it is classified as TSL4.\n",
    "\n",
    "More about those results:  \n",
    "Also, it is important to note the BLAST comparisons didn't turn up any additional TSL4-rated transcript ENST00000567329 (USP7-217) candidates.\n",
    "\n",
    "Keep in mind that this is a rough sketch at this time. Several classified in this simple scheme as 'MANE' will actually be unspliced/genomic, too. Plus, I'm sure some classified as 'neither' are some of the other USP7 transcripts Ensembl lists in the transcript table, but I haven't included a way to sort that for those that don't have a match to the RET_I 31-mer sequence. In other words, there's lots of other transcripts in this region, and so the process could be made to be much better at classifying. \n",
    "One could envision checking for splice junctions or lack thereof. Plus checking what positions in expected transcripts are spanned by the reads.    \n",
    "However, this  should give a good general idea of the rough number of USP7 transcripts that aren't TSL4-rated USP7-217 that has the retained intron.\n",
    "\n",
    "I also would be remiss not pointing out the 0.2% may be a gross overstimate. We only have one example in the one dataset. That is no way to assess. It may be pure chance that one example showed up in the 6.4 million reads. With only one it is hard to take an average. This is a classic case of a limited sample. Not to mention, there may be related biosamples that don't have it and indicate it is more rare. We can easily see why it is TSL4-rated after this and how Logan Search can be helpful if you want to go digging in the Sequence Read Archive (SRA) for evidence of your transcript of interest.\n",
    "\n",
    "I also think the results presented here suggest a lot of the hits to the query for the retained intron sequence could also be contamination or unspliced transcripts. If I had to do this all over again, I'd choose to make this demonstration for a transcript with an ususual splicing event and use that as a basis to investigate. That way I can look for evidence of the unsual splice junction and the possibility of genomic contamination or unspliced transcripts would not be a confounding factor. Also, I'd probably come up with a combination of scoring based on presence of an exact or similar to query sequences alone with assessment of the BLAST hits, taking into account the spanned positions, all combined to indicate a score. And then use that score to decide classification of each read. That being said, this endeavor parallels one plenty of researchers may face, and the fact this endeavor still worked to find an example of this poorly supported transcript speaks to the power of Logan Search.\n",
    "\n",
    "-----\n",
    "\n",
    "Enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
